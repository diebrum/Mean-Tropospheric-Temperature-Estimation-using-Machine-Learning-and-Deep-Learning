{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook brings the codes used in the paper submitted to Journal of Selected Topics On Applied Earth Observations and Remote Sensing (JSTARSS)\n",
        "\n",
        "Title of the paper: New Mean Tropospheric Temperature models based\n",
        "on Machine Learning Algorithms for Brazil"
      ],
      "metadata": {
        "id": "eG3UPPuU6Dw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the necessary libraries**"
      ],
      "metadata": {
        "id": "J5LOgl0X7Fq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,SimpleRNN,GRU\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import svm\n",
        "import joblib\n"
      ],
      "metadata": {
        "id": "5ZftRdwR7Qgx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Loading Data**"
      ],
      "metadata": {
        "id": "tfs9hiye-sGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Description of the datasets:\n",
        "- Files with the name 'train.txt' are the data used to train the models;\n",
        "- Files with the name 'target.txt' contais the target values, or the expected values for Tm, used in training as well;\n",
        "- Files with the name 'test.txt' are the input in the stage of test the models;\n",
        "- Files with the name 'eval.txt' contains the real Tm values and the values obtained by other models found in literature.  \n",
        "'''\n",
        "\n",
        "train_features=np.loadtxt('train.txt')\n",
        "train_labels=np.loadtxt('target.txt')\n",
        "test_features=np.loadtxt('test.txt')\n",
        "evaluation=np.loadtxt('eval.txt')\n",
        "\n"
      ],
      "metadata": {
        "id": "b4Psjvbo79Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Random Forest and Support Vector Regression, the Reshape operation must be performed.\n",
        "\n",
        "train_features=train_features.reshape(-1,2)\n",
        "train_labels=train_labels.reshape(-1,1)\n",
        "test_features=test_features.reshape(-1,2)"
      ],
      "metadata": {
        "id": "liKGB2G--a5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Neural Networks, the data must be normalized.\n",
        "\n",
        "train_features[:,0]=train_features[:,0]/1100\n",
        "train_features[:,1]=train_features[:,1]/310\n",
        "train_labels=train_labels/300\n",
        "test_features[:,0]=test_features[:,0]/1100\n",
        "test_features[:,1]=test_features[:,1]/310\n",
        "\n",
        "#After normalization, a reshape operation must be performed on train and test inputs.\n",
        "\n",
        "train_features = train_features.reshape(train_features.shape[0], train_features.shape[1], 1) \n",
        "test_features = test_features.reshape(test_features.shape[0], test_features.shape[1], 1) "
      ],
      "metadata": {
        "id": "EWHDsTzZ79Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jx1nea0p79Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qTyRUFR79YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simple Recurrent Neural Network (RNN)**"
      ],
      "metadata": {
        "id": "8Te5mL4y_k6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(2, return_sequences=False,input_shape=(2, 1)))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "#model.add(Dense(3, activation=\"tanh\"))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\") "
      ],
      "metadata": {
        "id": "ZKr7Zg5Y79aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Long-Short Term Memory Recurrent Neural Network (LSTM)**"
      ],
      "metadata": {
        "id": "tdbY9cvC_rFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(3, return_sequences=False,input_shape=(2, 1)))\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "#model.add(Dense(2, activation=\"relu\"))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")  "
      ],
      "metadata": {
        "id": "SBLFR1Ib79cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gated Recurrent Unit Neural Network (GRU)**"
      ],
      "metadata": {
        "id": "KXDYw4Cc_xWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Gated Recurrent Unit (GRU) \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(GRU(2, return_sequences=False,input_shape=(2, 1)))\n",
        "model.add(Dense(10, activation=\"relu\"))\n",
        "#model.add(Dense(10, activation=\"sigmoid\"))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "EODAzGfb79dw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Fit**"
      ],
      "metadata": {
        "id": "r3m_EBxmAA40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell must be run for the Neural Network models, according to the model you instantiate.\n",
        "\n",
        "model.fit(train_features, train_labels, batch_size=20,epochs=50, verbose=1)"
      ],
      "metadata": {
        "id": "q7zPFmBg8qIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Test**"
      ],
      "metadata": {
        "id": "o09ly9lMAacD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This cell performs the test of the neural network model.\n",
        "\n",
        "predictions=model.predict(test_features) # Make predictions\n",
        "pred=predictions*300 #Transforms the results to the scale of Tm values\n",
        "np.savetxt('cagr_GRU.txt',pred[:,0]) #Save the results in a .txt file.\n",
        "model.save('GRU_cagr.h5') #Save the keras model in a .h5 file"
      ],
      "metadata": {
        "id": "8mbOVoNT8qLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading a keras model and making predictions**"
      ],
      "metadata": {
        "id": "tb7EzQL2BCaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The names and values used in the examples are for representation purposes\n",
        "\n",
        "model = keras.models.load_model('fedn_LSTM.h5') #Loads the model\n",
        "\n",
        "#Making the predictions on a variable storing data from file\n",
        "\n",
        "prediction=model(data) #Consider data the values of surface temperature and pressure read from a .txt file for example\n",
        "\n",
        "#Making the predictions for one single input\n",
        "\n",
        "prediction=model(([291.7,901.6])) \n"
      ],
      "metadata": {
        "id": "2ThXlSHV8qOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "43MOE3Ev8qSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Regression (SVR)**"
      ],
      "metadata": {
        "id": "x97s1DLWDAxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVR( kernel=\"rbf\", C=1, gamma=0.1) #Instantiating the model\n",
        "\n",
        "clf.fit(train_features, train_labels) #Fit the model\n",
        "\n",
        "predictions=clf.predict(test_features) #Test the model\n",
        "\n",
        "np.savetxt('cagr_SVR.txt',predictions) #Save the predictions in a .txt file\n",
        "\n",
        "joblib.dump(clf, \"./SVR_cagr.joblib\") #Save the object model"
      ],
      "metadata": {
        "id": "KUcTWP8M79gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Regressor (RF)**"
      ],
      "metadata": {
        "id": "bb7WUmiyDIPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000,max_depth=7, random_state = 1) #Instantiating the model\n",
        "\n",
        "rf.fit(train_features, train_labels); #Fit the model\n",
        "\n",
        "predictions = rf.predict(test_features) #Test the model\n",
        "\n",
        "np.savetxt('cagr_RF.txt',predictions) #Save the predictions in a .txt file\n",
        "\n",
        "joblib.dump(rf, \"./RF_cagr.joblib\") #Save the object model"
      ],
      "metadata": {
        "id": "ANioKIZq79iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical** **evaluation**"
      ],
      "metadata": {
        "id": "qM0y_oWmD0UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(evaluation[:,0], pred) #Computes the Mean Squared Error using the real Tm values and predicted Tm values \n",
        "rmse=np.sqrt(mse) #Computes the Root Mean Squared Error\n"
      ],
      "metadata": {
        "id": "cgoedh1V79jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Computes the Huber Metric\n",
        "\n",
        "gamma=5\n",
        "\n",
        "erro=evaluation[:,0]-evaluation[:,8]\n",
        "erro=np.abs(erro)\n",
        "erros_menor=[]\n",
        "erros_maior=[]\n",
        "n=erro.shape[0]\n",
        "for i in range(n):\n",
        "  if erro[i]<=gamma:\n",
        "\n",
        "      erros_menor.append(erro[i])\n",
        "  else:\n",
        "      erros_maior.append(erro[i])\n",
        "    \n",
        "  \n",
        "erros_menor=np.asarray(erros_menor)\n",
        "erros_maior=np.asarray(erros_maior)\n",
        "\n",
        "\n",
        "\n",
        "huber_menor=(1/n)*np.sum(0.5*(erros_menor**2))\n",
        "\n",
        "huber_maior=(1/n)*np.sum(gamma*(np.abs(erros_maior)-0.5*gamma))\n",
        "huber_metric=(huber_maior+huber_menor)/2\n",
        "\n",
        "huber_metric"
      ],
      "metadata": {
        "id": "aHv7s_SE79lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O03QE_XO79n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CuNOXFLCc7z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}